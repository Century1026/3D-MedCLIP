{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "204dbfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/swin-tiny-patch4-window7-224 were not used when initializing SwinModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing SwinModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing SwinModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model weight from: ./pretrained/medclip-vit\n",
      "dict_keys(['img_embeds', 'text_embeds', 'logits', 'loss_value', 'logits_per_text'])\n"
     ]
    }
   ],
   "source": [
    "from medclip import MedCLIPModel, MedCLIPVisionModelViT\n",
    "from medclip import MedCLIPProcessor\n",
    "from PIL import Image\n",
    "\n",
    "# prepare for the demo image and texts\n",
    "processor = MedCLIPProcessor()\n",
    "image = Image.open('./example_data/view1_frontal.jpg')\n",
    "inputs = processor(\n",
    "    text=[\"lungs remain severely hyperinflated with upper lobe emphysema\", \n",
    "        \"opacity left costophrenic angle is new since prior exam ___ represent some loculated fluid cavitation unlikely\"], \n",
    "    images=image, \n",
    "    return_tensors=\"pt\", \n",
    "    padding=True\n",
    "    )\n",
    "\n",
    "# pass to MedCLIP model\n",
    "model = MedCLIPModel(vision_cls=MedCLIPVisionModelViT)\n",
    "model.from_pretrained()\n",
    "model.cuda()\n",
    "outputs = model(**inputs)\n",
    "print(outputs.keys())\n",
    "# dict_keys(['img_embeds', 'text_embeds', 'logits', 'loss_value', 'logits_per_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abe962d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/swin-tiny-patch4-window7-224 were not used when initializing SwinModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing SwinModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing SwinModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model weight from: ./pretrained/medclip-vit\n",
      "sample 10 num of prompts for Atelectasis from total 210\n",
      "sample 10 num of prompts for Cardiomegaly from total 15\n",
      "sample 10 num of prompts for Consolidation from total 192\n",
      "sample 10 num of prompts for Edema from total 18\n",
      "sample 10 num of prompts for Pleural Effusion from total 54\n",
      "{'logits': tensor([[0.3598, 0.4742, 0.1603, 0.2272, 0.3849]], device='cuda:0',\n",
      "       grad_fn=<StackBackward0>), 'class_names': ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']}\n"
     ]
    }
   ],
   "source": [
    "from medclip import MedCLIPModel, MedCLIPVisionModelViT\n",
    "from medclip import MedCLIPProcessor\n",
    "from medclip import PromptClassifier\n",
    "\n",
    "processor = MedCLIPProcessor()\n",
    "model = MedCLIPModel(vision_cls=MedCLIPVisionModelViT)\n",
    "model.from_pretrained()\n",
    "clf = PromptClassifier(model, ensemble=True)\n",
    "clf.cuda()\n",
    "\n",
    "# prepare input image\n",
    "from PIL import Image\n",
    "image = Image.open('./example_data/view1_frontal.jpg')\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "# prepare input prompt texts\n",
    "from medclip.prompts import generate_chexpert_class_prompts, process_class_prompts\n",
    "cls_prompts = process_class_prompts(generate_chexpert_class_prompts(n=10))\n",
    "inputs['prompt_inputs'] = cls_prompts\n",
    "\n",
    "# make classification\n",
    "output = clf(**inputs)\n",
    "print(output)\n",
    "# {'logits': tensor([[0.5154, 0.4119, 0.2831, 0.2441, 0.4588]], device='cuda:0',\n",
    "#       grad_fn=<StackBackward0>), 'class_names': ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
